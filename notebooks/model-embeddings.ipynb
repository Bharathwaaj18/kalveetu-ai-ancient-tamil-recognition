{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_path = \"/kaggle/input/tamil-kalveetu/tensorflow2/default/1/tamil_model.pth\"\ntrain_dir = \"/kaggle/input/augmented/augmented/train\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.serialization.add_safe_globals([torch.nn.Sequential])\n\nmodel = torch.load(\n    model_path,\n    map_location=device,\n    weights_only=False\n)\nmodel.to(device).eval()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_embedding(image_path):\n    img = Image.open(image_path).convert(\"RGB\")\n    tensor = transform(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        _, emb = model(tensor)          # model returns (logits, embedding)\n        emb = F.normalize(emb, p=2, dim=1)\n\n    return emb.cpu()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = sorted(os.listdir(train_dir))\nprototype_embeddings = []\n\nfor cls in class_names:\n    cls_folder = os.path.join(train_dir, cls)\n    img_name = os.listdir(cls_folder)[0]   # one representative image\n    img_path = os.path.join(cls_folder, img_name)\n\n    emb = extract_embedding(img_path)\n    prototype_embeddings.append(emb)\n\nprototype_matrix = torch.cat(prototype_embeddings)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def embedding_predict(image_path):\n    query_emb = extract_embedding(image_path)\n    similarities = F.cosine_similarity(query_emb, prototype_matrix)\n    idx = similarities.argmax().item()\n    return class_names[idx], similarities[idx].item()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_image = \"/kaggle/input/augmented/augmented/test/கௌ/aug_0_1.jpg\"\n\npred, score = embedding_predict(test_image)\npred, score\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}